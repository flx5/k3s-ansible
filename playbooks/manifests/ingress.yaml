apiVersion: v1
kind: Namespace
metadata:
  name: ingress-nginx
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: custom-headers
  namespace: ingress-nginx
data:
  X-Frame-Options: "DENY"
  X-Content-Type-Options: "nosniff"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: custom-error-pages
  namespace: ingress-nginx
data:
  403.html: |
    <!DOCTYPE html>
    <html lang="en">
    <head><title>Forbidden</title></head>
    <body>Forbidden</body>
    </html>
  404.html: |
    <!DOCTYPE html>
    <html lang="en">
    <head><title>PAGE NOT FOUND</title></head>
    <body>PAGE NOT FOUND</body>
    </html>
  500.html: |
    <!DOCTYPE html>
    <html lang="en">
    <head><title>INTERNAL SERVER ERROR</title></head>
    <body>INTERNAL SERVER ERROR</body>
    </html>
  503.html: |
    <!DOCTYPE html>
    <html lang="en">
    <head><title>SERVICE UNAVAILABLE</title></head>
    <body>SERVICE UNAVAILABLE</body>
    </html>
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: modsecurity-plugins
  namespace: ingress-nginx
data:
  empty-after.conf: |
    # no data
  empty-before.conf: |
    # no data
  empty-config.conf: |
    # no data
  nextcloud-rule-exclusions-before.conf: |
    {{ lookup('file', './nextcloud-rule-exclusions-before.conf') | indent(4) }}
---
apiVersion: helm.cattle.io/v1
kind: HelmChart
metadata:
  name: ingress-internal
  namespace: kube-system
spec:
  repo: https://kubernetes.github.io/ingress-nginx
  chart: ingress-nginx
  version: 4.12.1
  targetNamespace: ingress-nginx
  valuesContent: |-
    controller:
      add-headers: ingress-nginx/custom-headers
      config:
        # In accordance with hardening guide
        keep-alive: 10
        custom-http-errors: "403,404,503,500"
        hide-headers: X-Powered-By,Server
      # Must be the same as for kube vip due to externalTrafficPolicy: Local
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: node-role.kubernetes.io/master
                operator: Exists
            - matchExpressions:
              - key: node-role.kubernetes.io/control-plane
                operator: Exists
      electionID: internal-ingress-controller-leader
      ingressClass: internal-nginx  # default: nginx
      ingressClassResource:
        name: internal-nginx  # default: nginx
        enabled: true
        default: false
        controllerValue: "k8s.io/internal-ingress-nginx"  # default: k8s.io/ingress-nginx
      service:
        # Set to local to preserve the source ip and reduce the amount of hops (kube-vip should use the leader election to only advertise the nodes that have a pod running)
        externalTrafficPolicy: Local
        annotations: 
         kube-vip.io/loadbalancerIPs: 192.168.2.91
    defaultBackend:
      enabled: true
      image:
        registry: registry.k8s.io
        image: ingress-nginx/custom-error-pages
        tag: v1.1.2@sha256:49a5154b3f918aae436ae342ac410a947524f1da8a2f9c249b564a092cf44955
      extraVolumes:
      - name: custom-error-pages
        configMap:
          name: custom-error-pages
      extraVolumeMounts:
        - name: custom-error-pages
          mountPath: /www
---
apiVersion: helm.cattle.io/v1
kind: HelmChart
metadata:
  name: ingress-public
  namespace: kube-system
spec:
  repo: https://kubernetes.github.io/ingress-nginx
  chart: ingress-nginx
  version: 4.12.1
  targetNamespace: ingress-nginx
  valuesContent: |-
    controller:
      add-headers: ingress-nginx/custom-headers
      config:
        # In accordance with hardening guide
        keep-alive: 10
        custom-http-errors: "403,404,503,500"
        hide-headers: X-Powered-By,Server
        # Needed to allow snippets
        # allow-snippet-annotations: true
        # annotations-risk-level: Critical
        # WAF
        # Enables Modsecurity
        enable-modsecurity: "true"
        # Update ModSecurity config and rules
        modsecurity-snippet: |
          # this enables the mod security nextcloud plugin
          Include /etc/nginx/owasp-modsecurity-crs/plugins/nextcloud-rule-exclusions-before.conf

          # this enables the default OWASP Core Rule Set
          Include /etc/nginx/owasp-modsecurity-crs/nginx-modsecurity.conf
    
          # Enable prevention mode. Options: DetectionOnly,On,Off (default is DetectionOnly)
          SecRuleEngine On
    
          # Enable scanning of the request body
          SecRequestBodyAccess On
    
          # Enable XML and JSON parsing
          SecRule REQUEST_HEADERS:Content-Type "(?:text|application(?:/soap\+|/)|application/xml)/" \
            "id:200000,phase:1,t:none,t:lowercase,pass,nolog,ctl:requestBodyProcessor=XML"
    
          SecRule REQUEST_HEADERS:Content-Type "application/json" \
            "id:200001,phase:1,t:none,t:lowercase,pass,nolog,ctl:requestBodyProcessor=JSON"
    
          # Reject if larger (we could also let it pass with ProcessPartial)
          SecRequestBodyLimitAction Reject
    
          # Send ModSecurity audit logs to the stdout (only for rejected requests)
          SecAuditLog /dev/stdout
    
          # format the logs in JSON
          SecAuditLogFormat JSON
    
          # could be On/Off/RelevantOnly
          SecAuditEngine RelevantOnly
      extraVolumes:
      - name: plugins
        configMap:
          name: modsecurity-plugins
      extraVolumeMounts:
      - name: plugins
        mountPath: /etc/nginx/owasp-modsecurity-crs/plugins
      # Must be the same as for kube vip due to externalTrafficPolicy: Local
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: node-role.kubernetes.io/master
                operator: Exists
            - matchExpressions:
              - key: node-role.kubernetes.io/control-plane
                operator: Exists
      electionID: public-ingress-controller-leader
      ingressClass: public-nginx  # default: nginx
      ingressClassResource:
        name: public-nginx  # default: nginx
        enabled: true
        default: false
        controllerValue: "k8s.io/public-ingress-nginx"  # default: k8s.io/ingress-nginx
      service:
        # Set to local to preserve the source ip and reduce the amount of hops (kube-vip should use the leader election to only advertise the nodes that have a pod running)
        externalTrafficPolicy: Local
        annotations: 
         kube-vip.io/loadbalancerIPs: 192.168.2.93
    defaultBackend:
      enabled: true
      image:
        registry: registry.k8s.io
        image: ingress-nginx/custom-error-pages
        tag: v1.1.2@sha256:49a5154b3f918aae436ae342ac410a947524f1da8a2f9c249b564a092cf44955
      extraVolumes:
      - name: custom-error-pages
        configMap:
          name: custom-error-pages
      extraVolumeMounts:
        - name: custom-error-pages
          mountPath: /www
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: ingress-network-policy
  namespace: ingress-nginx
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/name: ingress-nginx
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
        - ipBlock:
            # Only allow ingress from lan
            cidr: 192.168.0.0/16
        - namespaceSelector:
            matchLabels:
              kubernetes.io/metadata.name: velero
  egress:
    - to:
        # Allow egress to all namespaces but not to lan
        - namespaceSelector: {}
    # Need to allow access to the API server for for controller-leader-lease
    # Allow egress to the service first (kubectl get svc kubernetes).
    # Then we also need to allow egress to the actual controller nodes:
    # https://pauldally.medium.com/accessing-kubernetes-api-server-when-there-is-an-egress-networkpolicy-af4435e005f9
    # Would be nicer if we would use cilium: https://docs.cilium.io/en/stable/security/policy/language/#entities-based
    - to:
        - ipBlock:

            cidr: 10.43.0.1/32
        {% for server in groups['server'] -%}
        - ipBlock:
            cidr: {{ server }}/32
        {% endfor +%}
---
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: allow-webhook-access-from-apiserver
  namespace: ingress-nginx
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/name: ingress-nginx
  policyTypes:
    - Ingress
  ingress:
    - from:
        # Admission Webhooks are called from the Kube-API Server.
        # This is using the flannel.1 interface of the controller servers.
        # Flannel is assigning each controller server it's own subnet.
        {% for subnet in range(256) -%}
        - ipBlock:
            cidr: 10.42.{{ subnet }}.0/32
        {% endfor +%}
      ports:
        - port: 8443